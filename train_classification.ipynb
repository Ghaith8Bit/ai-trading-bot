{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709587b5",
   "metadata": {},
   "source": [
    "# Cryptocurrency Classification Training\n",
    "This notebook demonstrates a from-scratch training pipeline to predict bullish hours using engineered features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b93ed8",
   "metadata": {},
   "source": [
    "## 1. Generate or load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f16519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from utils.build_dataset import generate_dataset\n",
    "\n",
    "RAW_CSV = Path('data/raw/BTCUSDT_1h.csv')\n",
    "OUTPUT_DIR = Path('data/processed/classification')\n",
    "VERSION = 'v2'\n",
    "\n",
    "# Generate dataset if it does not already exist\n",
    "if not (OUTPUT_DIR / f'X_{VERSION}.parquet').exists():\n",
    "    generate_dataset(\n",
    "        raw_path=str(RAW_CSV),\n",
    "        output_dir=str(OUTPUT_DIR),\n",
    "        version=VERSION,\n",
    "        task='classification',\n",
    "        horizon=3,\n",
    "        ml_logger=None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd56dcd2",
   "metadata": {},
   "source": [
    "## 2. Load processed features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f818f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = Path('data/processed/classification')\n",
    "X = pd.read_parquet(base / 'X_v2.parquet')\n",
    "y = pd.read_parquet(base / 'y_v2.parquet').squeeze()\n",
    "\n",
    "# Align indices and sort chronologically\n",
    "X = X.sort_index()\n",
    "y = y.loc[X.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a9458",
   "metadata": {},
   "source": [
    "## 3. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff0972",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score",
    "from sklearn.linear_model import LogisticRegression",
    "from sklearn.base import ClassifierMixin, BaseEstimator, ClassifierTags",
    "from xgboost import XGBClassifier",
    "import numpy as np",
    "",
    "# Patch to support xgboost with scikit-learn >=1.6",
    "def _patched_classifier_tags(self):",
    "    tags = BaseEstimator.__sklearn_tags__(self)",
    "    tags.estimator_type = \"classifier\"",
    "    tags.classifier_tags = ClassifierTags()",
    "    tags.target_tags.required = True",
    "    return tags",
    "ClassifierMixin.__sklearn_tags__ = _patched_classifier_tags",
    "",
    "# Search space for LogisticRegression",
    "lr = LogisticRegression(max_iter=1000)",
    "param_dist_lr = {",
    "    'C': np.logspace(-3, 1, 20),",
    "    'penalty': ['l2'],",
    "}",
    "",
    "# Search space for XGBoost",
    "xgb = XGBClassifier(eval_metric='logloss')",
    "param_dist_xgb = {",
    "    'n_estimators': [100, 200, 300],",
    "    'learning_rate': [0.01, 0.05, 0.1],",
    "    'max_depth': [3, 5, 7],",
    "}",
    "",
    "cv = TimeSeriesSplit(n_splits=3)",
    "",
    "search_lr = RandomizedSearchCV(lr, param_dist_lr, n_iter=10, cv=cv, scoring='roc_auc', n_jobs=-1, random_state=42)",
    "search_lr.fit(X_train, y_train)",
    "",
    "search_xgb = RandomizedSearchCV(xgb, param_dist_xgb, n_iter=10, cv=cv, scoring='roc_auc', n_jobs=1, random_state=42)",
    "search_xgb.fit(X_train, y_train)",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e1e2ec",
   "metadata": {},
   "source": [
    "## 5. Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48613237",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': search_lr.best_estimator_,\n",
    "    'XGBClassifier': search_xgb.best_estimator_,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    preds = (proba > 0.5).astype(int)\n",
    "    results[name] = {\n",
    "        'roc_auc': roc_auc_score(y_test, proba),\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'precision': precision_score(y_test, preds),\n",
    "        'recall': recall_score(y_test, preds),\n",
    "        'f1': f1_score(y_test, preds),\n",
    "    }\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046a09d",
   "metadata": {},
   "source": [
    "## 6. Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7aff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "best_name = max(results, key=lambda k: results[k]['roc_auc'])\n",
    "best_model = models[best_name]\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "model_path = Path('models') / f'classification_{best_name.lower()}_v2.joblib'\n",
    "dump(best_model, model_path)\n",
    "print('Saved', model_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
